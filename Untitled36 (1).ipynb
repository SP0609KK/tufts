{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71cca920",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 2) (1137919539.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    tufts_path = r\"\\\\path.xlsx\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 2)\n"
     ]
    }
   ],
   "source": [
    "def fetch_sot(sheets):\n",
    "    tufts_path = r\"\\\\path.xlsx\n",
    "    \n",
    "    xls_tufts = pd.ExcelFile(tufts_path)\n",
    "    \n",
    "    df_list=[]\n",
    "    \n",
    "    for sheet in sheets:\n",
    "        if sheet in xls.tufts.sheet_names:\n",
    "            df=pd.read_excel(tufts_path, sheet_name=sheet, dtype = str)\n",
    "            \n",
    "            for index, row in df.iterrows():\n",
    "            for col in range(len(row)):\n",
    "                # If the cell contains \"PRIMARY/SOLD PLAN\"\n",
    "                if row[col] == \"PRIMARY/SOLD PLAN\":\n",
    "                    # Fill all cells to the left with the value \"PRIMARY/SOLD PLAN\"\n",
    "                    for i in range(col - 1, -1, -1):\n",
    "                        df.iloc[index, i] = row[col]\n",
    "                        \n",
    "            unique_options = set()\n",
    "\n",
    "            for index, row in df.iterrows():\n",
    "                for cell in row:\n",
    "                    if isinstance(cell, str):  # Check if the cell is a string\n",
    "                        options = re.findall(r'OPTION \\d+', cell)  # Extract options using regex\n",
    "                        unique_options.update(options)\n",
    "\n",
    "            # Iterate through the DataFrame rows\n",
    "            for index, row in df.iterrows():\n",
    "                for col in range(len(row)):\n",
    "                    # If the cell contains any of the unique options\n",
    "                    for option in unique_options:\n",
    "                        if isinstance(row[col], str) and option in row[col]:\n",
    "                            # Fill all cells to the left with the corresponding value\n",
    "                            for i in range(col - 1, -1, -1):\n",
    "                                df.iloc[index, i] = row[col]\n",
    "                            break  # Break out of the loop once the option is found\n",
    "                            \n",
    "            # Find the index where \"GRAND TOTAL\" occurs in any column\n",
    "            grand_total_index = df[df.eq('GRAND TOTAL').any(axis=1)].index[0]\n",
    "\n",
    "            # Drop all rows after the index of \"GRAND TOTAL\"\n",
    "            df = df.iloc[:grand_total_index]\n",
    "\n",
    "            # Keeping only columns Unnamed: 4 to Unnamed: 7\n",
    "            df = df.iloc[:, 4:8]\n",
    "            \n",
    "            def shift_non_nan(row):\n",
    "                shifted_row = [np.nan] * len(row)\n",
    "                last_non_nan_index = None\n",
    "                for i, value in enumerate(row):\n",
    "                    if pd.notnull(value):\n",
    "                        if last_non_nan_index is None:\n",
    "                            shifted_row[0] = value\n",
    "                            last_non_nan_index = 0\n",
    "                        else:\n",
    "                            last_non_nan_index += 1\n",
    "                            shifted_row[last_non_nan_index] = value\n",
    "                return pd.Series(shifted_row)\n",
    "\n",
    "            # Apply the function to each row of the dataframe\n",
    "            df = df.apply(shift_non_nan, axis=1)\n",
    "            \n",
    "            benefit_plan_rows = df[df.apply(lambda row: 'Benefit Plan' in row.values, axis=1)]\n",
    "\n",
    "            # Merge cells to the right of 'Benefit Plan' rows\n",
    "            for index, row in benefit_plan_rows.iterrows():\n",
    "                # Find the index of the column where 'Benefit Plan' is located\n",
    "                benefit_plan_index = np.where(row == 'Benefit Plan')[0][0]\n",
    "                # Find non-NaN values to merge\n",
    "                non_nan_values = row.iloc[benefit_plan_index + 1:].dropna().tolist()\n",
    "                # Merge non-NaN values into a single cell\n",
    "                merged_value = ' '.join(str(cell) for cell in non_nan_values)\n",
    "                # Assign the merged value to the cell next to 'Benefit Plan'\n",
    "                df.at[index, benefit_plan_index + 1] = merged_value\n",
    "                \n",
    "            df = df.drop(columns=[2, 3])\n",
    "            \n",
    "            df = df.dropna()\n",
    "            \n",
    "            def split_rows(df):\n",
    "                new_rows = []\n",
    "                for index, row in df.iterrows():\n",
    "                    split_row = False  # Flag to check if splitting occurred for this row\n",
    "                    for column_name, cell_value in row.items():\n",
    "                        if ',' in str(cell_value):\n",
    "                            split_row = True  # Set flag to True if splitting occurred for any column\n",
    "                            details = str(cell_value).split(', ')\n",
    "                            for detail in details:\n",
    "                                new_row = row.copy()  # Copy the original row\n",
    "                                new_row[column_name] = detail.strip()  # Update the cell value\n",
    "                                new_rows.append(new_row)  # Append the new row to the list\n",
    "                            break  # Break out of the loop once splitting occurs for any column\n",
    "                    if not split_row:\n",
    "                        new_rows.append(row)  # Append the original row if no splitting occurred\n",
    "                df = pd.DataFrame(new_rows)  # Creating a new DataFrame with split rows\n",
    "                return df\n",
    "\n",
    "            # Call the function with the DataFrame\n",
    "            df = split_rows(df)\n",
    "            \n",
    "            df.index = range(len(df))\n",
    "            \n",
    "            # Words to check for deletion\n",
    "            words_to_delete = ['OP', 'IP', 'MD', 'X-Ray', 'Lab', 'Riders', 'Drug Benefit', 'Rating Group']\n",
    "\n",
    "            # Function to filter out rows containing specified words\n",
    "            def filter_rows(df, words_to_delete):\n",
    "                indices_to_drop = []  # List to store indices of rows to drop\n",
    "                # Iterate through each row\n",
    "                for index, row in df.iterrows():\n",
    "                    # Flag to check if any word to delete is found\n",
    "                    delete_row = False\n",
    "                    # Iterate through each cell value in the row\n",
    "                    for cell_value in row.values:\n",
    "                        # Check if any word to delete is present in the cell value\n",
    "                        for word in words_to_delete:\n",
    "                            if re.search(r'\\b' + word + r'\\b', str(cell_value)):\n",
    "                                # If any word is found, set delete_row flag to True\n",
    "                                delete_row = True\n",
    "                                break  # No need to continue checking for words in this row\n",
    "                        if delete_row:\n",
    "                            break  # No need to check further if any word is found in this row\n",
    "                    if delete_row:\n",
    "                        indices_to_drop.append(index)  # Store the index of the row to drop\n",
    "                # Drop the rows outside of the loop to avoid modifying DataFrame while iterating\n",
    "                df = df.drop(indices_to_drop)\n",
    "                return df\n",
    "\n",
    "            # Call the function with the DataFrame\n",
    "            df = filter_rows(df, words_to_delete)\n",
    "            \n",
    "            df = df.applymap(lambda x: str(x).replace('$', ' $') if isinstance(x, str) else x)\n",
    "            \n",
    "            # Extracting the words \"PCP\", \"SPC\", \"UC\", \"ER\", \"Ded\", and \"Coins\" into a separate column\n",
    "            df.insert(loc=1, column='Type', value=df[1].str.extract(r'(PCP|SPC|UC|ER|Ded|Coins|OOP)', expand=False))\n",
    "\n",
    "            # Fill NaN values in the \"Type\" column with a default value\n",
    "            df['Type'].fillna('', inplace=True)\n",
    "            \n",
    "            # Remove the words \"PCP\", \"SPC\", \"UC\", \"ER\", \"Ded\", and \"Coins\" from the actual column\n",
    "            df[1] = df[1].str.replace(r'(PCP|SPC|UC|ER|Ded|Coins|OOP)', '', regex=True)\n",
    "            \n",
    "            # Merge the first and second columns\n",
    "            df.insert(loc=0, column='Merged', value=df[0].astype(str) + \" \" + df['Type'].astype(str))\n",
    "\n",
    "            # Drop the 'Type' and the original first column\n",
    "            df.drop(columns=[0, 'Type'], inplace=True)\n",
    "            \n",
    "            # Set column names to empty strings\n",
    "            df.columns = [''] * len(df.columns)\n",
    "\n",
    "            # Reset index\n",
    "            df.reset_index(drop=True, inplace=True)\n",
    "            \n",
    "            # Row mapping dictionary\n",
    "            word_mapping = {\n",
    "                'In Network Copays PCP': 'INN PCP COPAY',\n",
    "                'In Network Copays SPC': 'INN SPEC COPAY',\n",
    "                'In Network Copays UC': 'INN URGENT CARE COPAY',\n",
    "                'In Network Copays ER': 'INN ER COPAY',\n",
    "                'In Net Ded/Coins/OOP Ded': 'INN DEDUCTIBLE',\n",
    "                'In Net Ded/Coins/OOP Coins': 'INN COINSURANCE',\n",
    "                'In Net Ded/Coins/OOP OOP': 'INN OOP Max.',\n",
    "                'Out of Network Ded': 'OON DEDUCTIBLE',\n",
    "                'Out of Network Coins': 'OON COINSURANCE',\n",
    "                'Out of Network OOP': 'OON OOP Max.'\n",
    "            }\n",
    "\n",
    "            # Replace words in the DataFrame using the mapping dictionary\n",
    "            df.replace(word_mapping, inplace=True)\n",
    "            \n",
    "            # Create a new DataFrame to store the result\n",
    "            df = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "            # Iterate over each row in the original DataFrame\n",
    "            for index, row in df.iterrows():\n",
    "                # Check if the row in the second column contains '/'\n",
    "                if '/' in row[1]:  # Assuming the second column is the one you want to check\n",
    "                    # Split the row into two rows if '/' has '$' before or after it\n",
    "                    parts = row[1].split('/')\n",
    "                    if ('$' in parts[0]) or ('$' in parts[1]):\n",
    "                        # Add 'IND' prefix to the first split row and 'FAM' to the second split row if necessary\n",
    "                        df.loc[len(df)] = ['IND ' + row[0], parts[0]]\n",
    "                        df.loc[len(df)] = ['FAM ' + row[0], parts[1]]\n",
    "                    else:\n",
    "                        df.loc[len(df)] = [row[0], row[1]]\n",
    "                else:\n",
    "                    # If no '/', append the row as it is to the new DataFrame\n",
    "                    df.loc[len(df)] = [row[0], row[1]]\n",
    "                    \n",
    "            df_list.append(df)\n",
    "            \n",
    "        else:\n",
    "            print('Sheet not found in SOT')\n",
    "            \n",
    "    return df_list\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a284439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize split_dfs to store split DataFrames\n",
    "split_dfs = []\n",
    "\n",
    "# Iterate through the processed_data DataFrame\n",
    "current_df = None\n",
    "for index, row in processed_data.iterrows():\n",
    "    # Check if the row starts with \"OPTION\"\n",
    "    if row[0].startswith('OPTION'):\n",
    "        # Check if there is an existing current_df and if it meets the length condition\n",
    "        if current_df is not None and len(current_df) >= 6:\n",
    "            # Append the current_df to split_dfs\n",
    "            split_dfs.append(current_df)\n",
    "        # Create a new DataFrame for the current section\n",
    "        current_df = pd.DataFrame(columns=processed_data.columns)\n",
    "    # Append the row to the current_df if it exists\n",
    "    if current_df is not None:\n",
    "        current_df = pd.concat([current_df, row.to_frame().T], ignore_index=True)\n",
    "\n",
    "# Check if there is a current_df at the end and if it meets the length condition\n",
    "if current_df is not None and len(current_df) >= 6:\n",
    "    # Append the current_df to split_dfs\n",
    "    split_dfs.append(current_df)\n",
    "\n",
    "# Add split DataFrames to the result list df_list\n",
    "df_list.extend(split_dfs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
