{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b364ce3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def process_folder(folder_path):\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.xlsx'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            process_excel(file_path)\n",
    "\n",
    "def process_excel(file_path):\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    df = pd.read_excel(file_path)\n",
    "\n",
    "    # Drop columns with more than 94% null values\n",
    "    null_percentage = df.isnull().mean() * 100\n",
    "    cols_to_drop = null_percentage[null_percentage > 94].index\n",
    "    df = df.drop(columns=cols_to_drop)\n",
    "\n",
    "    # Keep only specified phrases in the first column\n",
    "    phrases_to_keep = ['Annual Medical Deductible', 'Individual', 'Family', 'Annual Out-of-Pocket Limit', 'Primary Care Physician', 'Specialist', 'Urgent Care Center Services', 'Emergency Care']\n",
    "    df = df[df.iloc[:, 0].isin(phrases_to_keep)]\n",
    "\n",
    "    # Drop columns with all null values\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "\n",
    "    # Rename columns\n",
    "    new_col_names = {0: 'Field', 1: 'In Network', 2:'Out of Network'}\n",
    "    for idx, col_name in new_col_names.items():\n",
    "        if idx < len(df.columns):\n",
    "            df = df.rename(columns={df.columns[idx]: col_name})\n",
    "\n",
    "    # Split dataframe based on network type\n",
    "    if 'Out of Network' not in df.columns:\n",
    "        result_df = df.copy()\n",
    "    else:\n",
    "        df1 = pd.DataFrame({'Field':['In Network']})\n",
    "        df1 = pd.concat([df1, df[['Field', 'In Network']]])\n",
    "\n",
    "        df2 = pd.DataFrame({'Field':['Out of Network']})\n",
    "        df2 = pd.concat([df2, df[['Field', 'Out of Network']]])\n",
    "\n",
    "        result_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "    # Fill missing values and rename columns\n",
    "    result_df_filled = result_df.iloc[:, ::-1].fillna(method='ffill', axis=1).iloc[:,::-1]\n",
    "    result_df_filled = result_df_filled.drop(['Field'], axis=1, errors='ignore')\n",
    "    result_df_filled = result_df_filled.rename(columns={'In Network': 'Value'})\n",
    "\n",
    "    # Update specific fields\n",
    "    for i, row in result_df_filled.iterrows():\n",
    "        if row['Field'] == 'Annual Medical Deductible':\n",
    "            result_df_filled.at[i+1, 'Field'] = 'Individual Deductible'\n",
    "            result_df_filled.at[i+2, 'Field'] = 'Family Deductible'\n",
    "        elif row['Field'] == 'Annual Out-of-Pocket Limit':\n",
    "            result_df_filled.at[i+1, 'Field'] = 'Individual OOP'\n",
    "            result_df_filled.at[i+2, 'Field'] = 'Family OOP'\n",
    "\n",
    "    result_df_filled = result_df_filled[~result_df_filled['Field'].isin(['Annual Medical Deductible', 'Annual Out-of-Pocket Limit'])]\n",
    "\n",
    "    # Add 'Network Type' column\n",
    "    result_df_filled.insert(0, 'Network Type', result_df_filled['Field'].apply(lambda x: 'In Network' if x == 'In Network' else 'Out of Network' if x == 'Out of Network' else ''))\n",
    "\n",
    "    # Forward fill values until the next column contains certain keywords\n",
    "    network_col_index = result_df_filled.columns.get_loc('Network Type')\n",
    "    values_col_index = result_df_filled.columns.get_loc('Field')\n",
    "    for i in range(len(result_df_filled)):\n",
    "        if result_df_filled.iloc[i, network_col_index] in ['In Network', 'Out of Network']:\n",
    "            for j in range(i, len(result_df_filled)):\n",
    "                if result_df_filled.iloc[j, values_col_index] in ['Primary Care Physician', 'Specialist', 'Urgent Care Center Services', 'Emergency Care']:\n",
    "                    break\n",
    "                else:\n",
    "                    result_df_filled.iloc[j, network_col_index] = result_df_filled.iloc[i, network_col_index]\n",
    "\n",
    "    # Remove rows where values are repeated within the same row\n",
    "    result_df_filled = result_df_filled[~result_df_filled.apply(lambda row: len(set(row.dropna())) != len(row.dropna()), axis=1)]\n",
    "\n",
    "    # Merge first and second columns\n",
    "    result_df_filled.iloc[:, 0] = result_df_filled.iloc[:, 0] + ' ' + result_df_filled.iloc[:, 1]\n",
    "\n",
    "    # Drop the second column\n",
    "    result_df_filled.drop(columns=[result_df_filled.columns[1]], inplace=True)\n",
    "\n",
    "    # Update network type based on value content\n",
    "    for i, row in result_df_filled.iterrows():\n",
    "        if '%' in str(row['Value']):\n",
    "            result_df_filled.at[i, 'Network Type'] = 'Coinsurance'\n",
    "\n",
    "    coins_df = result_df_filled[result_df_filled['Network Type'] == 'Coinsurance']\n",
    "    coins_df = coins_df.drop_duplicates()\n",
    "\n",
    "    result_df = pd.concat([coins_df, result_df_filled[result_df_filled['Network Type'] != 'Coinsurance']])\n",
    "    result_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "# Example usage:\n",
    "process_folder(r'C:\\Users\\shres\\Downloads')  # Replace with your folder path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fff12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def process_folder(folder_path):\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.xlsx'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            try:\n",
    "                result_df = process_excel(file_path)\n",
    "                print(result_df)\n",
    "            except KeyError:\n",
    "                print(f\"Ignoring file: {file_path} - KeyError occurred.\")\n",
    "\n",
    "def process_excel(file_path):\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    df = pd.read_excel(file_path)\n",
    "\n",
    "    # Drop columns with more than 94% null values\n",
    "    null_percentage = df.isnull().mean() * 100\n",
    "    cols_to_drop = null_percentage[null_percentage > 94].index\n",
    "    df = df.drop(columns=cols_to_drop)\n",
    "\n",
    "    # Keep only specified phrases in the first column\n",
    "    phrases_to_keep = ['Annual Medical Deductible', 'Individual', 'Family', 'Annual Out-of-Pocket Limit', 'Primary Care Physician', 'Specialist', 'Urgent Care Center Services', 'Emergency Care']\n",
    "    df = df[df.iloc[:, 0].isin(phrases_to_keep)]\n",
    "\n",
    "    # Drop columns with all null values\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "\n",
    "    # Rename columns\n",
    "    new_col_names = {0: 'Field', 1: 'In Network', 2:'Out of Network'}\n",
    "    for idx, col_name in new_col_names.items():\n",
    "        if idx < len(df.columns):\n",
    "            df = df.rename(columns={df.columns[idx]: col_name})\n",
    "\n",
    "    # Split dataframe based on network type\n",
    "    if 'Out of Network' not in df.columns:\n",
    "        result_df = df.copy()\n",
    "    else:\n",
    "        df1 = pd.DataFrame({'Field':['In Network']})\n",
    "        df1 = pd.concat([df1, df[['Field', 'In Network']]])\n",
    "\n",
    "        df2 = pd.DataFrame({'Field':['Out of Network']})\n",
    "        df2 = pd.concat([df2, df[['Field', 'Out of Network']]])\n",
    "\n",
    "        result_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "    # Fill missing values and rename columns\n",
    "    result_df_filled = result_df.iloc[:, ::-1].fillna(method='ffill', axis=1).iloc[:,::-1]\n",
    "    result_df_filled = result_df_filled.drop(['Field'], axis=1, errors='ignore')\n",
    "    result_df_filled = result_df_filled.rename(columns={'In Network': 'Value'})\n",
    "\n",
    "    # Update specific fields\n",
    "    for i, row in result_df_filled.iterrows():\n",
    "        if row['Field'] == 'Annual Medical Deductible':\n",
    "            result_df_filled.at[i+1, 'Field'] = 'Individual Deductible'\n",
    "            result_df_filled.at[i+2, 'Field'] = 'Family Deductible'\n",
    "        elif row['Field'] == 'Annual Out-of-Pocket Limit':\n",
    "            result_df_filled.at[i+1, 'Field'] = 'Individual OOP'\n",
    "            result_df_filled.at[i+2, 'Field'] = 'Family OOP'\n",
    "\n",
    "    result_df_filled = result_df_filled[~result_df_filled['Field'].isin(['Annual Medical Deductible', 'Annual Out-of-Pocket Limit'])]\n",
    "\n",
    "    # Add 'Network Type' column\n",
    "    result_df_filled.insert(0, 'Network Type', result_df_filled['Field'].apply(lambda x: 'In Network' if x == 'In Network' else 'Out of Network' if x == 'Out of Network' else ''))\n",
    "\n",
    "    # Forward fill values until the next column contains certain keywords\n",
    "    network_col_index = result_df_filled.columns.get_loc('Network Type')\n",
    "    values_col_index = result_df_filled.columns.get_loc('Field')\n",
    "    for i in range(len(result_df_filled)):\n",
    "        if result_df_filled.iloc[i, network_col_index] in ['In Network', 'Out of Network']:\n",
    "            for j in range(i, len(result_df_filled)):\n",
    "                if result_df_filled.iloc[j, values_col_index] in ['Primary Care Physician', 'Specialist', 'Urgent Care Center Services', 'Emergency Care']:\n",
    "                    break\n",
    "                else:\n",
    "                    result_df_filled.iloc[j, network_col_index] = result_df_filled.iloc[i, network_col_index]\n",
    "\n",
    "    # Remove rows where values are repeated within the same row\n",
    "    result_df_filled = result_df_filled[~result_df_filled.apply(lambda row: len(set(row.dropna())) != len(row.dropna()), axis=1)]\n",
    "\n",
    "    # Merge first and second columns\n",
    "    result_df_filled.iloc[:, 0] = result_df_filled.iloc[:, 0] + ' ' + result_df_filled.iloc[:, 1]\n",
    "\n",
    "    # Drop the second column\n",
    "    result_df_filled.drop(columns=[result_df_filled.columns[1]], inplace=True)\n",
    "\n",
    "    # Update network type based on value content\n",
    "    for i, row in result_df_filled.iterrows():\n",
    "        if '%' in str(row['Value']):\n",
    "            result_df_filled.at[i, 'Network Type'] = 'Coinsurance'\n",
    "\n",
    "    coins_df = result_df_filled[result_df_filled['Network Type'] == 'Coinsurance']\n",
    "    coins_df = coins_df.drop_duplicates()\n",
    "\n",
    "    result_df = pd.concat([coins_df, result_df_filled[result_df_filled['Network Type'] != 'Coinsurance']])\n",
    "    result_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "# Example usage:\n",
    "process_folder(r'C:\\Users\\shres\\Downloads')  # Replace with your folder path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41188be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "\n",
    "def get_sheet_names(file_path):\n",
    "    wb = openpyxl.load_workbook(file_path, read_only=True)\n",
    "    sheet_names = wb.sheetnames\n",
    "    wb.close()\n",
    "    return sheet_names\n",
    "\n",
    "def process_folder(folder_path):\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.xlsx'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            try:\n",
    "                sheet_names = get_sheet_names(file_path)\n",
    "                for sheet_name in sheet_names:\n",
    "                    result_df = process_excel(file_path, sheet_name)\n",
    "                    print(result_df)\n",
    "            except KeyError:\n",
    "                print(f\"Ignoring file: {file_path} - KeyError occurred.\")\n",
    "\n",
    "def process_excel(file_path, sheet_name):\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "\n",
    "    # Drop columns with more than 94% null values\n",
    "    null_percentage = df.isnull().mean() * 100\n",
    "    cols_to_drop = null_percentage[null_percentage > 94].index\n",
    "    df = df.drop(columns=cols_to_drop)\n",
    "\n",
    "    # Keep only specified phrases in the first column\n",
    "    phrases_to_keep = ['Annual Medical Deductible', 'Individual', 'Family', 'Annual Out-of-Pocket Limit', 'Primary Care Physician', 'Specialist', 'Urgent Care Center Services', 'Emergency Care']\n",
    "    df = df[df.iloc[:, 0].isin(phrases_to_keep)]\n",
    "\n",
    "    # Drop columns with all null values\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "\n",
    "    # Rename columns\n",
    "    new_col_names = {0: 'Field', 1: 'In Network', 2:'Out of Network'}\n",
    "    for idx, col_name in new_col_names.items():\n",
    "        if idx < len(df.columns):\n",
    "            df = df.rename(columns={df.columns[idx]: col_name})\n",
    "\n",
    "    # Split dataframe based on network type\n",
    "    if 'Out of Network' not in df.columns:\n",
    "        result_df = df.copy()\n",
    "    else:\n",
    "        df1 = pd.DataFrame({'Field':['In Network']})\n",
    "        df1 = pd.concat([df1, df[['Field', 'In Network']]])\n",
    "\n",
    "        df2 = pd.DataFrame({'Field':['Out of Network']})\n",
    "        df2 = pd.concat([df2, df[['Field', 'Out of Network']]])\n",
    "\n",
    "        result_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "    # Fill missing values and rename columns\n",
    "    result_df_filled = result_df.iloc[:, ::-1].fillna(method='ffill', axis=1).iloc[:,::-1]\n",
    "    result_df_filled = result_df_filled.drop(['Field'], axis=1, errors='ignore')\n",
    "    result_df_filled = result_df_filled.rename(columns={'In Network': 'Value'})\n",
    "\n",
    "    # Update specific fields\n",
    "    for i, row in result_df_filled.iterrows():\n",
    "        if row['Field'] == 'Annual Medical Deductible':\n",
    "            result_df_filled.at[i+1, 'Field'] = 'Individual Deductible'\n",
    "            result_df_filled.at[i+2, 'Field'] = 'Family Deductible'\n",
    "        elif row['Field'] == 'Annual Out-of-Pocket Limit':\n",
    "            result_df_filled.at[i+1, 'Field'] = 'Individual OOP'\n",
    "            result_df_filled.at[i+2, 'Field'] = 'Family OOP'\n",
    "\n",
    "    result_df_filled = result_df_filled[~result_df_filled['Field'].isin(['Annual Medical Deductible', 'Annual Out-of-Pocket Limit'])]\n",
    "\n",
    "    # Add 'Network Type' column\n",
    "    result_df_filled.insert(0, 'Network Type', result_df_filled['Field'].apply(lambda x: 'In Network' if x == 'In Network' else 'Out of Network' if x == 'Out of Network' else ''))\n",
    "\n",
    "    # Forward fill values until the next column contains certain keywords\n",
    "    network_col_index = result_df_filled.columns.get_loc('Network Type')\n",
    "    values_col_index = result_df_filled.columns.get_loc('Field')\n",
    "    for i in range(len(result_df_filled)):\n",
    "        if result_df_filled.iloc[i, network_col_index] in ['In Network', 'Out of Network']:\n",
    "            for j in range(i, len(result_df_filled)):\n",
    "                if result_df_filled.iloc[j, values_col_index] in ['Primary Care Physician', 'Specialist', 'Urgent Care Center Services', 'Emergency Care']:\n",
    "                    break\n",
    "                else:\n",
    "                    result_df_filled.iloc[j, network_col_index] = result_df_filled.iloc[i, network_col_index]\n",
    "\n",
    "    # Remove rows where values are repeated within the same row\n",
    "    result_df_filled = result_df_filled[~result_df_filled.apply(lambda row: len(set(row.dropna())) != len(row.dropna()), axis=1)]\n",
    "\n",
    "    # Merge first and second columns\n",
    "    result_df_filled.iloc[:, 0] = result_df_filled.iloc[:, 0] + ' ' + result_df_filled.iloc[:, 1]\n",
    "\n",
    "    # Drop the second column\n",
    "    result_df_filled.drop(columns=[result_df_filled.columns[1]], inplace=True)\n",
    "\n",
    "    # Update network type based on value content\n",
    "    for i, row in result_df_filled.iterrows():\n",
    "        if '%' in str(row['Value']):\n",
    "            result_df_filled.at[i, 'Network Type'] = 'Coinsurance'\n",
    "\n",
    "    coins_df = result_df_filled[result_df_filled['Network Type'] == 'Coinsurance']\n",
    "    coins_df = coins_df.drop_duplicates()\n",
    "\n",
    "    result_df = pd.concat([coins_df, result_df_filled[result_df_filled['Network Type'] != 'Coinsurance']])\n",
    "    result_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Create a DataFrame with the sheet name as a row\n",
    "    sheet_name_row = pd.DataFrame({\"Name\": [\"Sheet Name\", sheet_name]})\n",
    "    \n",
    "    # Concatenate the sheet name row with the processed DataFrame\n",
    "    processed_df = pd.concat([sheet_name_row, result_df], ignore_index=True)\n",
    "    \n",
    "    return processed_df\n",
    "\n",
    "# Example usage:\n",
    "process_folder(r'C:\\Users\\shres\\Downloads')  # Replace with your folder path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaf4a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "\n",
    "def get_sheet_names(file_path):\n",
    "    try:\n",
    "        wb = openpyxl.load_workbook(file_path, read_only=True)\n",
    "        sheet_names = wb.sheetnames\n",
    "        wb.close()\n",
    "        return sheet_names\n",
    "    except KeyError:\n",
    "        print(f\"KeyError occurred while accessing sheet names in the file: {file_path}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def process_folder(folder_path):\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.xlsx'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            try:\n",
    "                sheet_names = get_sheet_names(file_path)\n",
    "                for sheet_name in sheet_names:\n",
    "                    result_df = process_excel(file_path, sheet_name)\n",
    "                    print(result_df)\n",
    "            except KeyError:\n",
    "                print(f\"Ignoring file: {file_path} - KeyError occurred.\")\n",
    "\n",
    "def process_excel(file_path, sheet_name):\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "\n",
    "    # Drop columns with more than 94% null values\n",
    "    null_percentage = df.isnull().mean() * 100\n",
    "    cols_to_drop = null_percentage[null_percentage > 94].index\n",
    "    df = df.drop(columns=cols_to_drop)\n",
    "\n",
    "    # Keep only specified phrases in the first column\n",
    "    phrases_to_keep = ['Annual Medical Deductible', 'Individual', 'Family', 'Annual Out-of-Pocket Limit', 'Primary Care Physician', 'Specialist', 'Urgent Care Center Services', 'Emergency Care']\n",
    "    df = df[df.iloc[:, 0].isin(phrases_to_keep)]\n",
    "\n",
    "    # Drop columns with all null values\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "\n",
    "    # Rename columns\n",
    "    new_col_names = {0: 'Field', 1: 'In Network', 2:'Out of Network'}\n",
    "    for idx, col_name in new_col_names.items():\n",
    "        if idx < len(df.columns):\n",
    "            df = df.rename(columns={df.columns[idx]: col_name})\n",
    "\n",
    "    # Split dataframe based on network type\n",
    "    if 'Out of Network' not in df.columns:\n",
    "        result_df = df.copy()\n",
    "    else:\n",
    "        df1 = pd.DataFrame({'Field':['In Network']})\n",
    "        df1 = pd.concat([df1, df[['Field', 'In Network']]])\n",
    "\n",
    "        df2 = pd.DataFrame({'Field':['Out of Network']})\n",
    "        df2 = pd.concat([df2, df[['Field', 'Out of Network']]])\n",
    "\n",
    "        result_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "    # Fill missing values and rename columns\n",
    "    result_df_filled = result_df.iloc[:, ::-1].fillna(method='ffill', axis=1).iloc[:,::-1]\n",
    "    result_df_filled = result_df_filled.drop(['Field'], axis=1, errors='ignore')\n",
    "    result_df_filled = result_df_filled.rename(columns={'In Network': 'Value'})\n",
    "\n",
    "    # Update specific fields\n",
    "    for i, row in result_df_filled.iterrows():\n",
    "        if row['Field'] == 'Annual Medical Deductible':\n",
    "            result_df_filled.at[i+1, 'Field'] = 'Individual Deductible'\n",
    "            result_df_filled.at[i+2, 'Field'] = 'Family Deductible'\n",
    "        elif row['Field'] == 'Annual Out-of-Pocket Limit':\n",
    "            result_df_filled.at[i+1, 'Field'] = 'Individual OOP'\n",
    "            result_df_filled.at[i+2, 'Field'] = 'Family OOP'\n",
    "\n",
    "    result_df_filled = result_df_filled[~result_df_filled['Field'].isin(['Annual Medical Deductible', 'Annual Out-of-Pocket Limit'])]\n",
    "\n",
    "    # Add 'Network Type' column\n",
    "    result_df_filled.insert(0, 'Network Type', result_df_filled['Field'].apply(lambda x: 'In Network' if x == 'In Network' else 'Out of Network' if x == 'Out of Network' else ''))\n",
    "\n",
    "    # Forward fill values until the next column contains certain keywords\n",
    "    network_col_index = result_df_filled.columns.get_loc('Network Type')\n",
    "    values_col_index = result_df_filled.columns.get_loc('Field')\n",
    "    for i in range(len(result_df_filled)):\n",
    "        if result_df_filled.iloc[i, network_col_index] in ['In Network', 'Out of Network']:\n",
    "            for j in range(i, len(result_df_filled)):\n",
    "                if result_df_filled.iloc[j, values_col_index] in ['Primary Care Physician', 'Specialist', 'Urgent Care Center Services', 'Emergency Care']:\n",
    "                    break\n",
    "                else:\n",
    "                    result_df_filled.iloc[j, network_col_index] = result_df_filled.iloc[i, network_col_index]\n",
    "\n",
    "    # Remove rows where values are repeated within the same row\n",
    "    result_df_filled = result_df_filled[~result_df_filled.apply(lambda row: len(set(row.dropna())) != len(row.dropna()), axis=1)]\n",
    "\n",
    "    # Merge first and second columns\n",
    "    result_df_filled.iloc[:, 0] = result_df_filled.iloc[:, 0] + ' ' + result_df_filled.iloc[:, 1]\n",
    "\n",
    "    # Drop the second column\n",
    "    result_df_filled.drop(columns=[result_df_filled.columns[1]], inplace=True)\n",
    "\n",
    "    # Update network type based on value content\n",
    "    for i, row in result_df_filled.iterrows():\n",
    "        if '%' in str(row['Value']):\n",
    "            result_df_filled.at[i, 'Network Type'] = 'Coinsurance'\n",
    "\n",
    "    coins_df = result_df_filled[result_df_filled['Network Type'] == 'Coinsurance']\n",
    "    coins_df = coins_df.drop_duplicates()\n",
    "\n",
    "    result_df = pd.concat([coins_df, result_df_filled[result_df_filled['Network Type'] != 'Coinsurance']])\n",
    "    result_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Create a DataFrame with the sheet name as a row\n",
    "    sheet_name_row = pd.DataFrame({\"Name\": [\"Sheet Name\", sheet_name]})\n",
    "    \n",
    "    # Concatenate the sheet name row with the processed DataFrame\n",
    "    processed_df = pd.concat([sheet_name_row, result_df], ignore_index=True)\n",
    "    \n",
    "    return processed_df\n",
    "\n",
    "# Example usage:\n",
    "process_folder(r'C:\\Users\\shres\\Downloads')  # Replace with your folder path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8955841d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "\n",
    "def get_workbook_name(file_path):\n",
    "    return os.path.basename(file_path)\n",
    "\n",
    "def process_folder(folder_path):\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.xlsx'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            try:\n",
    "                result_df = process_excel(file_path)\n",
    "                print(result_df)\n",
    "            except KeyError:\n",
    "                print(f\"Ignoring file: {file_path} - KeyError occurred.\")\n",
    "\n",
    "def process_excel(file_path):\n",
    "    workbook_name = get_workbook_name(file_path)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    df = pd.read_excel(file_path)\n",
    "\n",
    "    # Drop columns with more than 94% null values\n",
    "    null_percentage = df.isnull().mean() * 100\n",
    "    cols_to_drop = null_percentage[null_percentage > 94].index\n",
    "    df = df.drop(columns=cols_to_drop)\n",
    "\n",
    "    # Keep only specified phrases in the first column\n",
    "    phrases_to_keep = ['Annual Medical Deductible', 'Individual', 'Family', 'Annual Out-of-Pocket Limit', 'Primary Care Physician', 'Specialist', 'Urgent Care Center Services', 'Emergency Care']\n",
    "    df = df[df.iloc[:, 0].isin(phrases_to_keep)]\n",
    "\n",
    "    # Drop columns with all null values\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "\n",
    "    # Rename columns\n",
    "    new_col_names = {0: 'Field', 1: 'In Network', 2:'Out of Network'}\n",
    "    for idx, col_name in new_col_names.items():\n",
    "        if idx < len(df.columns):\n",
    "            df = df.rename(columns={df.columns[idx]: col_name})\n",
    "\n",
    "    # Split dataframe based on network type\n",
    "    if 'Out of Network' not in df.columns:\n",
    "        result_df = df.copy()\n",
    "    else:\n",
    "        df1 = pd.DataFrame({'Field':['In Network']})\n",
    "        df1 = pd.concat([df1, df[['Field', 'In Network']]])\n",
    "\n",
    "        df2 = pd.DataFrame({'Fields':['Out of Network']})\n",
    "        df2 = pd.concat([df2, df[['Field', 'Out of Network']]])\n",
    "\n",
    "        result_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "    # Fill missing values and rename columns\n",
    "    result_df_filled = result_df.iloc[:, ::-1].fillna(method='ffill', axis=1).iloc[:,::-1]\n",
    "    result_df_filled = result_df_filled.drop(['Fields', \"Out of Network\"], axis=1, errors='ignore')\n",
    "    result_df_filled = result_df_filled.rename(columns={'In Network': 'Value'})\n",
    "\n",
    "    # Update specific fields\n",
    "    for i, row in result_df_filled.iterrows():\n",
    "        if row['Field'] == 'Annual Medical Deductible':\n",
    "            result_df_filled.at[i+1, 'Field'] = 'Individual Deductible'\n",
    "            result_df_filled.at[i+2, 'Field'] = 'Family Deductible'\n",
    "        elif row['Field'] == 'Annual Out-of-Pocket Limit':\n",
    "            result_df_filled.at[i+1, 'Field'] = 'Individual OOP'\n",
    "            result_df_filled.at[i+2, 'Field'] = 'Family OOP'\n",
    "\n",
    "    result_df_filled = result_df_filled[~result_df_filled['Field'].isin(['Annual Medical Deductible', 'Annual Out-of-Pocket Limit'])]\n",
    "\n",
    "    # Add 'Network Type' column\n",
    "    result_df_filled.insert(0, 'Network Type', result_df_filled['Field'].apply(lambda x: 'In Network' if x == 'In Network' else 'Out of Network' if x == 'Out of Network' else ''))\n",
    "\n",
    "    # Forward fill values until the next column contains certain keywords\n",
    "    network_col_index = result_df_filled.columns.get_loc('Network Type')\n",
    "    values_col_index = result_df_filled.columns.get_loc('Field')\n",
    "    for i in range(len(result_df_filled)):\n",
    "        if result_df_filled.iloc[i, network_col_index] in ['In Network', 'Out of Network']:\n",
    "            for j in range(i, len(result_df_filled)):\n",
    "                if result_df_filled.iloc[j, values_col_index] in ['Primary Care Physician', 'Specialist', 'Urgent Care Center Services', 'Emergency Care']:\n",
    "                    break\n",
    "                else:\n",
    "                    result_df_filled.iloc[j, network_col_index] = result_df_filled.iloc[i, network_col_index]\n",
    "\n",
    "    # Remove rows where values are repeated within the same row\n",
    "    result_df_filled = result_df_filled[~result_df_filled.apply(lambda row: len(set(row.dropna())) != len(row.dropna()), axis=1)]\n",
    "\n",
    "    # Merge first and second columns\n",
    "    result_df_filled.iloc[:, 0] = result_df_filled.iloc[:, 0] + ' ' + result_df_filled.iloc[:, 1]\n",
    "\n",
    "    # Drop the second column\n",
    "    result_df_filled.drop(columns=[result_df_filled.columns[1]], inplace=True)\n",
    "\n",
    "    # Update network type based on value content\n",
    "    for i, row in result_df_filled.iterrows():\n",
    "        if '%' in str(row['Value']):\n",
    "            result_df_filled.at[i, 'Network Type'] = 'Coinsurance'\n",
    "\n",
    "    coins_df = result_df_filled[result_df_filled['Network Type'] == 'Coinsurance']\n",
    "    coins_df = coins_df.drop_duplicates()\n",
    "\n",
    "    result_df = pd.concat([coins_df, result_df_filled[result_df_filled['Network Type'] != 'Coinsurance']])\n",
    "    result_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Add a row at the beginning with workbook name\n",
    "    result_df.loc[-1] = ['Name', workbook_name]\n",
    "    result_df.index = result_df.index + 1\n",
    "    result_df = result_df.sort_index()\n",
    "\n",
    "    return result_df\n",
    "\n",
    "# Example usage:\n",
    "process_folder(r'C:\\Users\\shres\\Downloads')  # Replace with your folder path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6eb1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def get_workbook_names(file_path):\n",
    "    workbook_name = os.path.basename(file_path).split('.')[0]\n",
    "    mns_match = re.match(r'.*(MNS.*)', workbook_name)\n",
    "    if mns_match:\n",
    "        mns_id = mns_match.group(1)\n",
    "        workbook_name = workbook_name.replace(mns_id, '')\n",
    "        return workbook_name.strip(), mns_id.strip()\n",
    "    else:\n",
    "        return workbook_name.strip(), ''\n",
    "\n",
    "def process_folder(folder_path):\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.xlsx'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            try:\n",
    "                result_df = process_excel(file_path)\n",
    "                print(result_df)\n",
    "            except KeyError:\n",
    "                print(f\"Ignoring file: {file_path} - KeyError occurred.\")\n",
    "\n",
    "def process_excel(file_path):\n",
    "    workbook_name, mns_id = get_workbook_names(file_path)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    df = pd.read_excel(file_path)\n",
    "\n",
    "    # Drop columns with more than 94% null values\n",
    "    null_percentage = df.isnull().mean() * 100\n",
    "    cols_to_drop = null_percentage[null_percentage > 94].index\n",
    "    df = df.drop(columns=cols_to_drop)\n",
    "\n",
    "    # Keep only specified phrases in the first column\n",
    "    phrases_to_keep = ['Annual Medical Deductible', 'Individual', 'Family', 'Annual Out-of-Pocket Limit', 'Primary Care Physician', 'Specialist', 'Urgent Care Center Services', 'Emergency Care']\n",
    "    df = df[df.iloc[:, 0].isin(phrases_to_keep)]\n",
    "\n",
    "    # Drop columns with all null values\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "\n",
    "    # Rename columns\n",
    "    new_col_names = {0: 'Field', 1: 'In Network', 2:'Out of Network'}\n",
    "    for idx, col_name in new_col_names.items():\n",
    "        if idx < len(df.columns):\n",
    "            df = df.rename(columns={df.columns[idx]: col_name})\n",
    "\n",
    "    # Split dataframe based on network type\n",
    "    if 'Out of Network' not in df.columns:\n",
    "        result_df = df.copy()\n",
    "    else:\n",
    "        df1 = pd.DataFrame({'Field':['In Network']})\n",
    "        df1 = pd.concat([df1, df[['Field', 'In Network']]])\n",
    "\n",
    "        df2 = pd.DataFrame({'Fields':['Out of Network']})\n",
    "        df2 = pd.concat([df2, df[['Field', 'Out of Network']]])\n",
    "\n",
    "        result_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "    # Fill missing values and rename columns\n",
    "    result_df_filled = result_df.iloc[:, ::-1].fillna(method='ffill', axis=1).iloc[:,::-1]\n",
    "    result_df_filled = result_df_filled.drop(['Fields', 'Out of Network'], axis=1, errors='ignore')\n",
    "    result_df_filled = result_df_filled.rename(columns={'In Network': 'Value'})\n",
    "\n",
    "    # Update specific fields\n",
    "    for i, row in result_df_filled.iterrows():\n",
    "        if row['Field'] == 'Annual Medical Deductible':\n",
    "            result_df_filled.at[i+1, 'Field'] = 'Individual Deductible'\n",
    "            result_df_filled.at[i+2, 'Field'] = 'Family Deductible'\n",
    "        elif row['Field'] == 'Annual Out-of-Pocket Limit':\n",
    "            result_df_filled.at[i+1, 'Field'] = 'Individual OOP'\n",
    "            result_df_filled.at[i+2, 'Field'] = 'Family OOP'\n",
    "\n",
    "    result_df_filled = result_df_filled[~result_df_filled['Field'].isin(['Annual Medical Deductible', 'Annual Out-of-Pocket Limit'])]\n",
    "\n",
    "    # Add 'Network Type' column\n",
    "    result_df_filled.insert(0, 'Network Type', result_df_filled['Field'].apply(lambda x: 'In Network' if x == 'In Network' else 'Out of Network' if x == 'Out of Network' else ''))\n",
    "\n",
    "    # Forward fill values until the next column contains certain keywords\n",
    "    network_col_index = result_df_filled.columns.get_loc('Network Type')\n",
    "    values_col_index = result_df_filled.columns.get_loc('Field')\n",
    "    for i in range(len(result_df_filled)):\n",
    "        if result_df_filled.iloc[i, network_col_index] in ['In Network', 'Out of Network']:\n",
    "            for j in range(i, len(result_df_filled)):\n",
    "                if result_df_filled.iloc[j, values_col_index] in ['Primary Care Physician', 'Specialist', 'Urgent Care Center Services', 'Emergency Care']:\n",
    "                    break\n",
    "                else:\n",
    "                    result_df_filled.iloc[j, network_col_index] = result_df_filled.iloc[i, network_col_index]\n",
    "\n",
    "    # Remove rows where values are repeated within the same row\n",
    "    result_df_filled = result_df_filled[~result_df_filled.apply(lambda row: len(set(row.dropna())) != len(row.dropna()), axis=1)]\n",
    "\n",
    "    # Merge first and second columns\n",
    "    result_df_filled.iloc[:, 0] = result_df_filled.iloc[:, 0] + ' ' + result_df_filled.iloc[:, 1]\n",
    "\n",
    "    # Drop the second column\n",
    "    result_df_filled.drop(columns=[result_df_filled.columns[1]], inplace=True)\n",
    "\n",
    "    # Update network type based on value content\n",
    "    for i, row in result_df_filled.iterrows():\n",
    "        if '%' in str(row['Value']):\n",
    "            result_df_filled.at[i, 'Network Type'] = 'Coinsurance'\n",
    "\n",
    "    coins_df = result_df_filled[result_df_filled['Network Type'] == 'Coinsurance']\n",
    "    coins_df = coins_df.drop_duplicates()\n",
    "\n",
    "    result_df = pd.concat([coins_df, result_df_filled[result_df_filled['Network Type'] != 'Coinsurance']])\n",
    "    result_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Add rows at the beginning with workbook names\n",
    "    result_df.loc[-1] = ['Name', workbook_name]\n",
    "    result_df.loc[-2] = ['MNS ID', mns_id]\n",
    "    result_df.index = result_df.index + 2\n",
    "    result_df = result_df.sort_index()\n",
    "\n",
    "    return result_df\n",
    "\n",
    "# Example usage:\n",
    "process_folder(r'C:\\Users\\shres\\Downloads')  # Replace with your folder path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
